{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Cleaned_Name</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "      <th>Review_Days</th>\n",
       "      <th>Response_Days</th>\n",
       "      <th>Predicted_Category</th>\n",
       "      <th>Probabilities</th>\n",
       "      <th>Mapped_Category</th>\n",
       "      <th>Hygiene</th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Atmosphere</th>\n",
       "      <th>Value for Money</th>\n",
       "      <th>Service Issue</th>\n",
       "      <th>Positive Review</th>\n",
       "      <th>Food Options</th>\n",
       "      <th>Review_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stop eating at this place, I have visited bang...</td>\n",
       "      <td>stop eating place visited bangalores nd punes ...</td>\n",
       "      <td>pramod kumar</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Quality, taste, or freshness issues with foo...</td>\n",
       "      <td>[0.9965850710868835, 0.9946374893188477, 0.844...</td>\n",
       "      <td>['Food Quality', 'Hygiene', 'Service Issue']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10-05-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Food 2/5\\nService 2/5\\nAmbience 2/5 …</td>\n",
       "      <td>food service ambience</td>\n",
       "      <td>abhinav deep</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>['Poor customer service or staff behavior', 'Q...</td>\n",
       "      <td>[0.8227755427360535, 0.7571902871131897]</td>\n",
       "      <td>['Service Issue', 'Food Quality']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07-11-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Idiotic varieties for the price they have char...</td>\n",
       "      <td>idiotic varieties price charged varieties boil...</td>\n",
       "      <td>vijay nammi</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Quality, taste, or freshness issues with foo...</td>\n",
       "      <td>[0.9860756993293762, 0.98301100730896]</td>\n",
       "      <td>['Food Quality', 'Value for Money']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07-10-2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I am posting this live now, this is one of the...</td>\n",
       "      <td>posting live one worst places dont visit pathe...</td>\n",
       "      <td>surya ajay</td>\n",
       "      <td>High</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>High Satisfaction</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>['Poor customer service or staff behavior', 'Q...</td>\n",
       "      <td>[0.992651641368866, 0.9484805464744568]</td>\n",
       "      <td>['Service Issue', 'Food Quality']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07-11-2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>We are pure vegetarians, I ordered veg biryani...</td>\n",
       "      <td>pure vegetarians ordered veg biryani swiggy go...</td>\n",
       "      <td>sai hithesh</td>\n",
       "      <td>Low</td>\n",
       "      <td>Non-Urgent</td>\n",
       "      <td>No Response</td>\n",
       "      <td>180</td>\n",
       "      <td>-1</td>\n",
       "      <td>['Poor customer service or staff behavior', 'C...</td>\n",
       "      <td>[0.9473494291305542, 0.8612152338027954, 0.833...</td>\n",
       "      <td>['Service Issue', 'Value for Money', 'Food Qua...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10-05-2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                             Review  \\\n",
       "0      0  Stop eating at this place, I have visited bang...   \n",
       "1      1              Food 2/5\\nService 2/5\\nAmbience 2/5 …   \n",
       "2      2  Idiotic varieties for the price they have char...   \n",
       "3      3  I am posting this live now, this is one of the...   \n",
       "4      4  We are pure vegetarians, I ordered veg biryani...   \n",
       "\n",
       "                                      Cleaned_Review  Cleaned_Name Severity  \\\n",
       "0  stop eating place visited bangalores nd punes ...  pramod kumar     High   \n",
       "1                              food service ambience  abhinav deep   Medium   \n",
       "2  idiotic varieties price charged varieties boil...   vijay nammi     High   \n",
       "3  posting live one worst places dont visit pathe...    surya ajay     High   \n",
       "4  pure vegetarians ordered veg biryani swiggy go...   sai hithesh      Low   \n",
       "\n",
       "      Urgency Customer_Satisfaction  Review_Days  Response_Days  \\\n",
       "0      Urgent           No Response          180             -1   \n",
       "1  Non-Urgent     High Satisfaction          365            365   \n",
       "2      Urgent           No Response           30             -1   \n",
       "3      Urgent     High Satisfaction          365            365   \n",
       "4  Non-Urgent           No Response          180             -1   \n",
       "\n",
       "                                  Predicted_Category  \\\n",
       "0  ['Quality, taste, or freshness issues with foo...   \n",
       "1  ['Poor customer service or staff behavior', 'Q...   \n",
       "2  ['Quality, taste, or freshness issues with foo...   \n",
       "3  ['Poor customer service or staff behavior', 'Q...   \n",
       "4  ['Poor customer service or staff behavior', 'C...   \n",
       "\n",
       "                                       Probabilities  \\\n",
       "0  [0.9965850710868835, 0.9946374893188477, 0.844...   \n",
       "1           [0.8227755427360535, 0.7571902871131897]   \n",
       "2             [0.9860756993293762, 0.98301100730896]   \n",
       "3            [0.992651641368866, 0.9484805464744568]   \n",
       "4  [0.9473494291305542, 0.8612152338027954, 0.833...   \n",
       "\n",
       "                                     Mapped_Category  Hygiene  Food Quality  \\\n",
       "0       ['Food Quality', 'Hygiene', 'Service Issue']        1             1   \n",
       "1                  ['Service Issue', 'Food Quality']        0             1   \n",
       "2                ['Food Quality', 'Value for Money']        0             1   \n",
       "3                  ['Service Issue', 'Food Quality']        0             1   \n",
       "4  ['Service Issue', 'Value for Money', 'Food Qua...        0             1   \n",
       "\n",
       "   Atmosphere  Value for Money  Service Issue  Positive Review  Food Options  \\\n",
       "0           0                0              1                0             0   \n",
       "1           0                0              1                0             0   \n",
       "2           0                1              0                0             0   \n",
       "3           0                0              1                0             0   \n",
       "4           0                1              1                0             0   \n",
       "\n",
       "  Review_Date  \n",
       "0  10-05-2024  \n",
       "1  07-11-2023  \n",
       "2  07-10-2024  \n",
       "3  07-11-2023  \n",
       "4  10-05-2024  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"E:\\Gradious_Final_Project\\database\\Final_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_add = ['Service Issue', 'Food Options', 'Food Quality', 'Atmosphere', 'Value for Money', 'Hygiene', 'Positive Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split Data into Training and Test Sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['Cleaned_Review'], df[categories_to_add], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert Labels to Tensors\n",
    "train_labels = torch.tensor(train_labels.values).float()\n",
    "test_labels = torch.tensor(test_labels.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Custom Dataset Class\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):  # Corrected constructor method name\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):  # Corrected method name\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):  # Corrected method name\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
    "test_dataset = ReviewDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model for classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Standard binary cross-entropy loss\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, accumulation_steps=4):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation function\n",
    "# def evaluate(model, test_loader, threshold=0.5):\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in test_loader:\n",
    "#             inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "#             labels = batch['labels'].cpu().numpy()\n",
    "#             outputs = model(**inputs)\n",
    "#             preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "#             # Apply threshold for multi-label classification\n",
    "#             preds = (preds > threshold).astype(int)\n",
    "#             all_preds.extend(preds)\n",
    "#             all_labels.extend(labels)\n",
    "\n",
    "#     return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 0.1104\n",
      "Epoch 2/3, Training Loss: 0.0802\n",
      "Epoch 3/3, Training Loss: 0.0611\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = ['Service Issue', \"Food Quality\", \"Atmosphere\", \"Value for Money\", \"Hygiene\",\"Food Options\",\"Positive Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].cpu().numpy()  # True labels\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).cpu().numpy()  # Get probabilities\n",
    "            \n",
    "            # Initialize predictions\n",
    "            binary_preds = np.zeros((preds.shape[0], preds.shape[1]))\n",
    "\n",
    "            # Process predictions\n",
    "            for idx, prob in enumerate(preds):\n",
    "                # Step 1: Check for categories with probability > threshold\n",
    "                predicted_categories = []\n",
    "                probabilities = []\n",
    "\n",
    "                for i, score in enumerate(prob):\n",
    "                    if score > threshold:  # Using threshold passed to the function\n",
    "                        predicted_categories.append(category_labels[i])\n",
    "                        probabilities.append(score)\n",
    "\n",
    "                # Convert the predicted categories to binary format\n",
    "                for category in category_labels:\n",
    "                    if category in predicted_categories:\n",
    "                        binary_preds[idx, category_labels.index(category)] = 1\n",
    "\n",
    "            all_preds.append(binary_preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Convert lists to arrays\n",
    "    return np.vstack(all_preds), np.vstack(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Usage of the Evaluate Function\n",
    "predicted_labels, true_labels = evaluate(model, test_loader, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of true labels: 841\n",
      "Length of predicted labels: 841\n"
     ]
    }
   ],
   "source": [
    "# Check the lengths\n",
    "print(\"Length of true labels:\", true_labels.shape[0])\n",
    "print(\"Length of predicted labels:\", predicted_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Service Issue       0.86      0.84      0.85       392\n",
      "   Food Quality       0.65      0.40      0.49       278\n",
      "     Atmosphere       0.85      0.78      0.82       465\n",
      "Value for Money       0.70      0.49      0.57       103\n",
      "        Hygiene       0.83      0.44      0.57       184\n",
      "   Food Options       0.69      0.74      0.72        58\n",
      "Positive Review       0.77      0.57      0.66       160\n",
      "\n",
      "      micro avg       0.80      0.65      0.72      1640\n",
      "      macro avg       0.76      0.61      0.67      1640\n",
      "   weighted avg       0.79      0.65      0.71      1640\n",
      "    samples avg       0.80      0.70      0.71      1640\n",
      "\n",
      "Accuracy: 0.38406658739595717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "e:\\Gradious_Final_Project\\abr\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report\n",
    "predicted_labels_binary = (predicted_labels > 0.5).astype(float)  # Binary representation based on probabilities\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(true_labels, predicted_labels_binary, target_names=category_labels))\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, predicted_labels_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was excellent and the service was great!\n",
      "Predicted Categories: ['Positive Review']\n",
      "Probabilities: [0.917658]\n",
      "-----\n",
      "Review: Service is bad\n",
      "Predicted Categories: ['Service Issue']\n",
      "Probabilities: [0.9763981]\n",
      "-----\n",
      "Review: atmosphere, hygience, food options is worst\n",
      "Predicted Categories: ['Atmosphere', 'Value for Money', 'Food Options']\n",
      "Probabilities: [0.8749844, 0.58649784, 0.88801455]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def classify_reviews(model, reviews, category_labels, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Tokenize the reviews (ensure you have a tokenizer defined)\n",
    "    tokenized_reviews = tokenizer(reviews, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_reviews)\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy()  # Get probabilities\n",
    "\n",
    "        for prob in preds:\n",
    "            predicted_categories = []\n",
    "            probabilities = []\n",
    "\n",
    "            # Step 1: Check for categories with probability > threshold\n",
    "            for i, score in enumerate(prob):\n",
    "                if score > threshold:\n",
    "                    predicted_categories.append(category_labels[i])\n",
    "                    probabilities.append(score)\n",
    "\n",
    "            # Step 2: If no categories above threshold, select the category with the highest probability\n",
    "            if not predicted_categories:\n",
    "                max_prob = max(prob)\n",
    "                max_category = category_labels[prob.tolist().index(max_prob)]\n",
    "                predicted_categories.append(max_category)\n",
    "                probabilities.append(max_prob)\n",
    "\n",
    "            all_preds.append(predicted_categories)\n",
    "            all_probs.append(probabilities)\n",
    "\n",
    "    return all_preds, all_probs\n",
    "\n",
    "# Sample usage\n",
    "sample_reviews = [\n",
    "    \"The food was excellent and the service was great!\",\n",
    "    \"Service is bad\",\n",
    "    \"atmosphere, hygience, food options is worst\"\n",
    "]\n",
    "\n",
    "predicted_categories, predicted_probabilities = classify_reviews(model, sample_reviews, category_labels, threshold=0.5)\n",
    "\n",
    "# Display results\n",
    "for review, categories, probs in zip(sample_reviews, predicted_categories, predicted_probabilities):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Categories: {categories}\")\n",
    "    print(f\"Probabilities: {probs}\")\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to E:\\Gradious_Final_Project\\model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory to save the model and tokenizer\n",
    "model_save_path = 'E:\\Gradious_Final_Project\\model'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f'Model and tokenizer saved to {model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
